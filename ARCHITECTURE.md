# AI Model Response Evaluator - System Architecture

This document outlines the system architecture, design decisions, and technical implementation details of the AI Model Response Evaluator platform.

## ğŸ—ï¸ High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      USER INTERFACE LAYER                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Web Browser (HTML/CSS/JavaScript)                             â”‚
â”‚  â€¢ Responsive design with mobile support                       â”‚
â”‚  â€¢ Real-time status updates and progress tracking              â”‚
â”‚  â€¢ Dynamic model selection and GPU memory controls             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ HTTP/HTTPS
                  â”‚ REST API Calls
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    APPLICATION LAYER                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Flask Web Framework (Python 3.7+)                            â”‚
â”‚  â€¢ RESTful API endpoints                                       â”‚
â”‚  â€¢ Request validation and error handling                       â”‚
â”‚  â€¢ Session management and state tracking                       â”‚
â”‚  â€¢ Async task coordination                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚           â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  BUSINESS  â”‚ â”‚  DATA ACCESS â”‚
      â”‚   LOGIC    â”‚ â”‚    LAYER     â”‚
      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     SERVICE LAYER                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  GeminiQuerier   â”‚  â”‚   Database   â”‚  â”‚ PydanticAI       â”‚  â”‚
â”‚  â”‚                  â”‚  â”‚   Manager    â”‚  â”‚ Wrapper          â”‚  â”‚
â”‚  â”‚ â€¢ Dual-mode      â”‚  â”‚              â”‚  â”‚                  â”‚  â”‚
â”‚  â”‚   querying       â”‚  â”‚ â€¢ SQLite     â”‚  â”‚ â€¢ Ollama         â”‚  â”‚
â”‚  â”‚ â€¢ Response       â”‚  â”‚   operations â”‚  â”‚   integration    â”‚  â”‚
â”‚  â”‚   parsing        â”‚  â”‚ â€¢ History    â”‚  â”‚ â€¢ GPU management â”‚  â”‚
â”‚  â”‚ â€¢ Error handling â”‚  â”‚   tracking   â”‚  â”‚ â€¢ Search tools   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚               â”‚               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EXTERNAL APIs    â”‚ â”‚   DATABASE   â”‚ â”‚    LOCAL SERVICES         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Google Gemini   â”‚ â”‚  SQLite DB   â”‚ â”‚ â€¢ Ollama Server           â”‚
â”‚   2.5 Pro API     â”‚ â”‚              â”‚ â”‚   (http://localhost:11434)â”‚
â”‚ â€¢ Tavily Search   â”‚ â”‚ Tables:      â”‚ â”‚ â€¢ Model Management        â”‚
â”‚   API             â”‚ â”‚ - responses  â”‚ â”‚ â€¢ GPU Memory Control      â”‚
â”‚                   â”‚ â”‚ - evaluationsâ”‚ â”‚ â€¢ OpenAI Compatible API   â”‚
â”‚                   â”‚ â”‚ - batch_jobs â”‚ â”‚                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ§© Component Architecture

### 1. Frontend Layer (Web Interface)

**Technology Stack:**
- **HTML5**: Semantic markup with accessibility considerations
- **CSS3**: Responsive design with Flexbox/Grid layouts
- **Vanilla JavaScript**: No external frameworks for simplicity
- **WebSocket**: (Future) Real-time updates for long-running operations

**Key Components:**
```javascript
// Main application state
- currentResponseId: Tracks active response pair
- currentPrompt: Current user input
- currentHistory: Cached response history

// UI Controllers
- ModelSelector: Dynamic model dropdown population
- ResponseRenderer: Formats and displays AI responses  
- HistoryManager: Search and load previous responses
- GPUController: Memory monitoring and cleanup
```

**Design Patterns:**
- **Module Pattern**: Isolated functionality in namespace objects
- **Observer Pattern**: Event-driven UI updates
- **Command Pattern**: GPU management operations

### 2. Backend Layer (Flask Application)

**Technology Stack:**
- **Flask 2.3+**: Lightweight WSGI web framework
- **Python 3.7+**: Core application language
- **SQLite**: Embedded database for simplicity
- **dotenv**: Environment variable management

**Core Modules:**

#### `app.py` - Main Application
```python
class GeminiQuerier:
    """Unified AI model interface"""
    - query_gemini_without_search()
    - query_gemini_with_search() 
    - query_model_without_search()  # Unified interface
    - query_model_with_search()     # Unified interface
    - evaluate_with_ollama()
    - get_available_models()
    
# API Routes
- /                              # Web interface
- /api/query-gemini             # Dual-mode querying
- /api/evaluate-response        # Custom evaluations
- /api/gemini-history          # Response history
- /api/available-models        # Model discovery
- /api/gpu-cleanup             # Memory management
```

#### `pydantic_ai_wrapper.py` - Ollama Integration
```python
class PydanticAIOllamaWrapper:
    """Advanced Ollama integration with GPU management"""
    - query_ollama_without_search()
    - query_ollama_with_search()
    - unload_model()              # Individual model cleanup
    - unload_all_models()         # Batch cleanup
    - get_loaded_models()         # Status monitoring

class TavilySearchTool:
    """AI-optimized web search integration"""
    - search()                    # Execute search queries
    - format_results()            # Structure for LLM consumption
```

### 3. Data Layer

#### Database Schema Design

```sql
-- Core response storage
CREATE TABLE gemini_responses (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    prompt TEXT NOT NULL,
    prompt_hash TEXT NOT NULL,              -- MD5 for deduplication
    model_name VARCHAR(100),                -- Model attribution
    response_without_search TEXT NOT NULL,
    thinking_without_search TEXT,           -- Reasoning transparency
    response_with_search TEXT NOT NULL,
    thinking_with_search TEXT,
    grounding_info TEXT,                    -- JSON search metadata
    error_without_search TEXT,              -- Error tracking
    error_with_search TEXT
);

-- Evaluation tracking
CREATE TABLE evaluations (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    gemini_response_id INTEGER NOT NULL,   -- Foreign key
    evaluation_prompt TEXT NOT NULL,       -- Custom prompt used
    ollama_model TEXT NOT NULL,           -- Evaluation model
    used_without_search BOOLEAN,          -- Response mode tracking
    used_with_search BOOLEAN,
    evaluation_result TEXT,
    error_message TEXT,
    FOREIGN KEY (gemini_response_id) REFERENCES gemini_responses (id)
);
```

**Design Decisions:**
- **SQLite**: Simplicity for single-user applications
- **JSON Storage**: Flexible schema for grounding_info
- **Error Tracking**: Separate error columns for debugging
- **Foreign Keys**: Referential integrity between responses and evaluations

### 4. Integration Layer

#### External API Integration

**Google Gemini 2.5 Pro**
```python
# Configuration
- API Key: GOOGLE_API_KEY environment variable
- Endpoint: Google GenAI REST API
- Features: Thinking process, search tools, structured responses

# Error Handling
- Exponential backoff (5s, 15s, 45s)
- Response validation
- Partial failure recovery
```

**Ollama Integration**  
```python
# Configuration
- Base URL: http://localhost:11434/v1 (OpenAI-compatible)
- Models: Dynamic discovery via `ollama list`
- Memory: Native keep_alive parameter management

# Advanced Features
- GPU memory monitoring via `ollama ps`
- Individual model unloading
- Batch cleanup operations
```

**Tavily Search API**
```python
# Configuration  
- API Key: TAVILY_API_KEY environment variable
- Endpoint: https://api.tavily.com/search
- Features: AI-optimized results, clean content extraction

# Integration
- Seamless pydantic_ai tool integration
- Structured result formatting
- Error fallback handling
```

## ğŸ”„ Data Flow Architecture

### 1. Query Processing Flow

```
User Input (Prompt + Model)
    â†“
Input Validation & Sanitization  
    â†“
Model Route Determination
    â”œâ”€ Gemini 2.5 Pro â†’ Google GenAI API
    â””â”€ Ollama Models â†’ PydanticAI Wrapper
    â†“
Parallel Execution:
    â”œâ”€ Query WITHOUT Search
    â””â”€ Query WITH Search (+ Tavily/Google Search)
    â†“
Response Processing & Parsing
    â”œâ”€ Extract thinking process
    â”œâ”€ Extract final response  
    â””â”€ Extract grounding information
    â†“
Database Storage (with model attribution)
    â†“
Return Structured Response to Frontend
```

### 2. Evaluation Processing Flow

```
User Evaluation Request
    â”œâ”€ Response ID
    â”œâ”€ Custom Evaluation Prompt  
    â””â”€ Selected Ollama Model
    â†“
Response Retrieval from Database
    â†“
Template Processing
    â”œâ”€ Replace {original_prompt}
    â”œâ”€ Replace {gemini_without_search_*}
    â””â”€ Replace {gemini_with_search_*}
    â†“
Ollama Model Execution
    â†“
Evaluation Result Processing
    â†“
Database Storage (linked to original response)
    â†“
Return Evaluation to Frontend
```

### 3. GPU Management Flow

```
GPU Status Request
    â†“
Execute `ollama ps` Command
    â†“
Parse Model Information
    â”œâ”€ Model Names
    â”œâ”€ Memory Usage
    â”œâ”€ Processor Assignment
    â””â”€ Timeout Information
    â†“
Format for Frontend Display
    â†“
Enable Individual/Batch Unload Operations
    â†“
Execute Unload via Ollama API
    â”œâ”€ Send keep_alive=0 request
    â””â”€ Monitor success/failure
    â†“
Update Frontend Status
```

## ğŸš€ Performance Architecture

### 1. Caching Strategy

**Application-Level Caching:**
- Model discovery results (refreshed periodically)
- Response history (cached with invalidation)
- GPU status information (short-term cache)

**Database Optimization:**
- Indexes on frequently queried columns (timestamp, model_name)
- Prompt hash for duplicate detection
- Connection pooling for concurrent requests

### 2. Resource Management

**Memory Management:**
```python
# Ollama GPU Memory
- Automatic model unloading after timeout
- Manual cleanup via API endpoints
- Memory threshold monitoring

# Application Memory  
- Lazy loading of large datasets
- Streaming for large responses
- Garbage collection optimization
```

**Concurrency Handling:**
- Async support for long-running operations
- Thread-safe database operations
- Request queuing for resource-intensive operations

### 3. Scalability Considerations

**Horizontal Scaling:**
- Stateless application design
- External database option (PostgreSQL/MySQL)
- Load balancer support

**Vertical Scaling:**
- Multi-GPU support for Ollama
- Memory-mapped file caching
- CPU-intensive task optimization

## ğŸ›¡ï¸ Security Architecture

### 1. API Security

**Input Validation:**
```python
- Prompt sanitization (XSS prevention)
- Parameter validation (type checking)
- Request size limits
- Rate limiting (configurable)
```

**Authentication & Authorization:**
```python
# Current: Server-side API key management
# Future: JWT tokens, OAuth2, role-based access
```

### 2. Data Security

**Environment Variables:**
- Sensitive API keys stored in .env
- No hardcoded secrets in source code
- Production-ready secret management support

**Database Security:**
- SQLite file permissions
- Connection string protection
- Query parameterization (SQL injection prevention)

### 3. Network Security

**API Endpoints:**
- HTTPS support (configurable)
- CORS policy configuration
- Request/response sanitization

## ğŸ”§ Configuration Architecture

### 1. Environment-Based Configuration

```python
# Required Configuration
GOOGLE_API_KEY=           # Gemini API access
TAVILY_API_KEY=           # Search functionality

# Optional Configuration  
OLLAMA_BASE_URL=          # Ollama server location
FLASK_ENV=                # Development/Production
LOG_LEVEL=                # Logging verbosity
```

### 2. Feature Flags

```python
# Configurable Features
ENABLE_GPU_MONITORING=    # GPU memory tracking
ENABLE_CACHING=           # Response caching
ENABLE_RATE_LIMITING=     # API rate limits
ENABLE_CORS=              # Cross-origin requests
```

## ğŸ“Š Monitoring & Observability

### 1. Logging Architecture

**Structured Logging:**
```python
- Request/Response logging
- Error tracking with stack traces
- Performance metrics (response times)
- GPU memory usage tracking
```

**Log Levels:**
- DEBUG: Detailed troubleshooting information
- INFO: General application flow
- WARNING: Recoverable issues
- ERROR: Error conditions requiring attention

### 2. Metrics Collection

**Application Metrics:**
- Request count and latency
- Model usage statistics
- Error rates by endpoint
- GPU memory utilization

**Business Metrics:**
- Response quality scores
- Model performance comparisons
- User engagement patterns

## ğŸ”„ Future Architecture Considerations

### 1. Microservices Migration

**Potential Service Breakdown:**
```
â”œâ”€â”€ API Gateway Service
â”œâ”€â”€ Model Management Service  
â”œâ”€â”€ Evaluation Service
â”œâ”€â”€ Search Integration Service
â”œâ”€â”€ Database Service
â””â”€â”€ GPU Management Service
```

### 2. Advanced Features

**Batch Processing:**
- Queue-based architecture
- Background job processing
- Progress tracking and notifications

**Real-time Features:**
- WebSocket integration
- Live response streaming
- Real-time collaboration

**Machine Learning Pipeline:**
- Response quality prediction
- Automated evaluation scoring
- Model recommendation system

---

## ğŸ—ï¸ Development Guidelines

### 1. Code Organization

```
app.py                     # Main Flask application
â”œâ”€â”€ Database functions     # Data access layer
â”œâ”€â”€ GeminiQuerier class   # Business logic
â””â”€â”€ API endpoints         # Presentation layer

pydantic_ai_wrapper.py    # External integrations
â”œâ”€â”€ TavilySearchTool      # Search functionality  
â””â”€â”€ PydanticAIOllamaWrapper # Ollama + GPU management

templates/new_index.html   # Frontend interface
â”œâ”€â”€ HTML structure        # Semantic markup
â”œâ”€â”€ CSS styling          # Responsive design
â””â”€â”€ JavaScript logic     # Interactive functionality
```

### 2. Testing Strategy

**Unit Testing:**
- Individual function testing
- Mock external API calls
- Database operation testing

**Integration Testing:**  
- End-to-end API workflows
- Database migration testing
- External service integration

**Performance Testing:**
- Load testing for concurrent users
- Memory usage under load
- GPU memory management efficiency

---

This architecture provides a solid foundation for the AI Model Response Evaluator while maintaining flexibility for future enhancements and scalability requirements.